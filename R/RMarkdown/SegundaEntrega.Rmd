---
title: "Segunda entrega"
author: "Diego Cubides,Larry castro, Tomas Mendez y Jersson avila"
date: "`r Sys.Date()`"
output: pdf_document
fontSize: 12pt
lang: es.MX
toc: TRUE
---
Link del repositorio: https://github.com/DiegoCubides/SegundaEntrega
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) 
library(knitr)
library(psych)
library(caret)
folder <-  dirname(rstudioapi::getSourceEditorContext()$path )
wall.distance <-read_csv(paste0(folder,"/dataset_wall_distance.csv"))
dataset <- read_csv(paste0(folder,"/dataset_wall_distance.csv"))
wall.distance2 <- read_csv(paste0(folder,"/dataset_wall_distance.csv"))
type.wall.distance <-read_csv(paste0(folder,"/dataset_type_wall_distance.csv"))
datase_prueba_lineal <- read_csv(paste0(folder,"/DATASET_PRUEBA_LINEAL.csv"))
datasetprueba <-read_csv(paste0(folder,"/type_wall_distance_prueba.csv"))
##
```

## Introducción

El presente reporte está basado en la implementación de un aprendizaje de máquina para poder predecir tres tipos de obstáculos mediante el algoritmo de Knn y la distancia bajo un modelo lineal y otro multilíneal de dos sensores incorporados en un carro a control remoto. Este robot fue implementado en Arduino y una app móvil con el fin de obtener datos de un sensor infrarrojo y un ultrasónico a distancias y obstáculos diferentes.

## Materiales

-   Sensor ultrasónico US-016
-   Sensor Infrarrojo 2Y0A21 F
-   Modulo puente h l298n
-   Carro a control remoto
-   bluetooth hc-05
-   Arduino UNO

## Software

-   RStudio
-   Arduino
-   App inventor
-   Excel
-   PLX-DAQ

## Procedimiento

- 1.1 adquisision de datos

Se programo un carro a control remoto vía bluetooth capaz de moverse a diferentes velocidades y en cualquier dirección, este fue controlado con una app creada en app inventor la cual permitio controlar el movimiento del carro y enviar la acción para que envié el dato censado en ese momento.

<div>

<p style="text-align:center;">

![App](app.png){width="472"}

</p>

</div>

<div>

<p style="text-align:center;">

![Carro](carro.png){withd="1%" width="285"}

</p>

</div>

Usando la comunicación Serial entre el Arduino y el módulo bluetooth se pudieron captar los datos de los sensores en Excel, para poder comunicar Excel con el Arduino se usó el software PLZ-DAQ

<div>

<p style="text-align:center;">

![PLX-DAQ](plx.png){withd="1%" width="221"}

</p>

</div>

- 1.2 Modelo lineal y regresion multilineal

Luego de tener el dataset de los datos tomados se carga la libreria tidyverse y el dataset

```{r, include=TRUE,echo=TRUE,eval=FALSE}
library(tidyverse)
folder <-  dirname(rstudioapi::getSourceEditorContext()$path )
wall.distance <-read_csv(paste0(folder,"/dataset_wall_distance.csv"))


```

Se hace el analisis exploratorio de datos para el dataset

```{r include=TRUE, echo=TRUE, eval=TRUE, warning=FALSE}

kable(summary(wall.distance))
```

De la tabla se puede identificar los valores maximos y minimos que se captaron con los sensores, de igual manera los valores por el primer quartil y el tercer cuartil

```{r include=TRUE, echo=TRUE, eval=TRUE, warning=FALSE}
hist(wall.distance$INFRARED,breaks = 10)
hist(wall.distance$ULTRASONIC,breaks = 10)

```

Debido a que la variable predictora es la distancia se tiene que pasar como factor,Graficando cada dato del sensor con la función hist se puede ver que los datos están distribuidos y que son viables para hacer aprendizaje de maquina

```{r include=TRUE, echo=TRUE, eval=TRUE, warning=FALSE}
wall.distance2$`DISTANCE(cm)` <-as.factor(wall.distance2$`DISTANCE(cm)`)
pairs(wall.distance[c("INFRARED","ULTRASONIC")]
,pch=25
,bg=c("green","blue3","gray","yellow","green3","pink","brown","black","red","orange")[unclass(wall.distance2$`DISTANCE(cm)`)])

```

Cuando se captaron los datos se identificó que un sensor crece inversamente al otro, graficando todos los datos en función a la distancia se notó que tienen una buena distribución y que se logran identificar grupos en todos los datos

```{r}
pairs.panels(wall.distance2[c("INFRARED","ULTRASONIC")]
             ,pch=21,bg=c("green","blue3","gray","yellow","green3","pink","brown","black","red","orange")[unclass(wall.distance2$`DISTANCE(cm)`)])
```

En esta grafica se ve mejor la relacion de las varibales y se ve que tiene una relacion negativa de -0.9, siendo esto un factor muy importante para poder hacer el aprendizaje de maquina

```{r}
kable(prop.table(table(wall.distance$`DISTANCE(cm)`)))
```

de los 110 datos que se obtuvieron hay la misma cantidad en cada distancia identificada -regresion lineal para sensor infrarojo

```{r}

x <- dataset$INFRARED
y <- dataset$`DISTANCE(cm)`
b=cov(x,y)/var(x)
a=mean(y)-b*mean(x)
a+b*121
```

-   regresion lineal para sensor infrarojo

-   Regresion Multilineal Para la regresion multilineal se van a tener dos predictores los cuales son los datos del infrarojo y del ultrasonico, se hace cross validation con el dataset dividiendlo en un 70% para entramiento y un 30% para prueba

```{r include=TRUE}
predictors <- c( "INFRARED", "ULTRASONIC")
sample.index <- sample(1:nrow(wall.distance)
                       ,nrow(wall.distance)*0.7
                       ,replace = F)
train.data  <-  wall.distance[sample.index
                                   ,c(predictors,"DISTANCE(cm)")
                                   ,drop=F]
test.data  <-  wall.distance[-sample.index
                                  ,c(predictors,"DISTANCE(cm)")
                                  ,drop=F]
```

Con la funcion lm se hace el modelo en funcion a la distancia y los datos con los que se va a entrenar son los del train.data

```{r eval=TRUE}
model<- lm(`DISTANCE(cm)` ~ INFRARED + ULTRASONIC,train.data)
summary(model)
predictions <- predict(model,test.data)
predictions
```

Para el caso del modelo multilineal se logra identificar que la variable que mas tiene relevancia en el entrenamiento es la de ULTRASOINIC, de los 33 datos que se tenian para hacer el test de prueba el modelo predijo correctamente las distancias de todos, para ver el error cuadratico medio se hizo lo siguiente

```{r}
RMSE.df <- data.frame(predicted = predictions
                      ,reales=test.data$`DISTANCE(cm)`
                      ,RSE = sqrt((predictions - test.data$`DISTANCE(cm)`)^2))
promedio_error <- sum(RMSE.df$RSE)/nrow(RMSE.df )
kable(head(RMSE.df))
promedio_error

```

- 2.1 Adquisición de datos

Para el modelo multilineal se obtuvieron nuevas medidas y una nueva variable la cual es el tipo de obstaculo, de las 4 variables se obtuvieron 198 muestras.

```{r}
kable(head(type.wall.distance))
```

```{r}
hist(type.wall.distance$INFRARED,breaks = 50)
hist(type.wall.distance$ULTRASONIC,breaks = 50)
```

A diferencia del primer dataset, en este se obtuvieron valores por fuera del rango normal como lo muestra la grafica del sensor ultrasonico.

```{r}
kable(summary(type.wall.distance))
```

Con la funcion summary se puede ver una division de los datos tanto del infrarojo como el del ultrasonido y cuales fueron sus valores maximos y minimos.

```{r}
type.wall.distance$TYPE <-as.factor(type.wall.distance$TYPE)

```

Debido a que la variable predictora es el tipo de obstaculo se tiene que pasar como factor, de cada

```{r}
plot(type.wall.distance[1:2]
     ,main=c("yellow = plano,blue=concavo,green=convexo")
     ,pch=21,bg=c("green","blue3","yellow")[unclass(type.wall.distance$TYPE)])
library(psych)
pairs.panels(type.wall.distance[1:2]
             ,main=c("yellow = plano,blue=concavo,green=convexo")
             ,pch=21,bg=c("green","blue3","yellow")[unclass(type.wall.distance$TYPE)])
```

En este dataset se cambio mucho la relacion entre las variables, se tiene una relacion del 0.03 que no es un buen indicio para aprendizaje de maquina pero aun asi se logran identificiar los tres grupos visualemente.

```{r}
dummy <- dummyVars(" ~ TYPE",data = type.wall.distance)

newdata <- data.frame(predict(dummy,newdata = type.wall.distance))

type.wall.distance <- cbind(type.wall.distance,newdata)
kable(head(type.wall.distance))
```

Se hace one hot encoding para la varibale TYPE, se tienen nuevas variables dummy y estas seran usadas como varibales predictoras para el aprendizaje de maquina.

```{r }

sample.index <- sample(1:nrow(type.wall.distance)
                       ,nrow(type.wall.distance)*0.7
                       ,replace = F)
predictors <- c("INFRARED","ULTRASONIC","TYPE.CONCAVA","TYPE.CONVEXA","TYPE.PLANA")


train.data  <-  type.wall.distance[sample.index
                                   ,c(predictors,"TYPE")
                                   ,drop=F]
test.data  <-  type.wall.distance[-sample.index
                                   ,c(predictors,"TYPE")
                                   ,drop=F]
```

para hacer el entrenamiento se hizo cross validation dividiendo el dataset en el 70% para entrenamiento y el 30% para prueba

```{r}
##KNN
ctrl <- trainControl(method = "cv",p=0.7) #variable de control
Knnfit <- train(TYPE ~ INFRARED+ULTRASONIC+TYPE.CONCAVA+TYPE.CONVEXA+TYPE.PLANA
                ,data = train.data
                ,method = "knn", trControl = ctrl
                ,preProcess= c("range")
                ,tuneLength=20)

Knnpredict <- predict(Knnfit,newdata = test.data)
confusionMatrix(Knnpredict
                ,test.data$TYPE)
```

Se entrena el algoritmo Knn en funcion de la variable TYPE y las variables predictoras son INFRARED,ULTRASONIC,TYPE.CONCAVA,TYPE.CONVEXA y TYPE.PLANA

con la matriz de confusion 3x3 se mira que de las muestras de test.data el algoritmo predice todas correctamente, tambien el accuary es de 1 y el p-value es menor a 2.2e-16 siendo este un valor muy importante estadisticamente.

de igual manera se ve la sensitividad y la especificidad son del 1.

```{r}
Knnpredict
```

## Validacion de modelos

Para la validacion de los tres  modelos se tomaron muestras  fuera del rango de las que se usaron  para el entrenamiento del algoritmo,de esta manera se pudo comprobar el rendimiento y la presicion modelos creados. para los nuevos datos se usaron rangos entre los 65cm y 85cm con un intervalo de 5cm.

- Validacion modelo lineal por sensor 
Luego de tomar los datos se obtiene un nuevo dataset con laS medidas fuera del rango de entrenamiento.
```{r}
kable(datase_prueba_lineal)
```
Se realizo la prueba del modelo con algunos valores y se obtuvo las siguientes respuestas:

- Modelo Lineal Infrarojo 
```{r echo=FALSE}

x <- wall.distance$INFRARED
y <- wall.distance$`DISTANCE(cm)`
b=cov(x,y)/var(x)
a=mean(y)-b*mean(x)
a+b* 212
a+b* 223
a+b* 231
a+b* 235
a+b* 247




```
Con los resultados se pudo concluir que el modelo del sensor infrarojo no tiene buena prediccion ya que estan los valores muy fuera de la respuesta esperada, esto se debe a que este sensor varia mucho los datos de las muestras y no tiene buena presicion.

- Modelo Lineal Ultrasonico
```{r echo=FALSE}
##Linear Regression For Ultrasonic Sensor
x <- wall.distance$ULTRASONIC
y <- wall.distance$`DISTANCE(cm)`
b=cov(x,y)/var(x)
a=mean(y)-b*mean(x)
a+b* 218
a+b* 240
a+b* 261
a+b* 276
a+b* 291

```

Para el modelo lineal ultrasonco se obtuvo una muy buena prediccion, el error entre el valor calculado y el valor real es muy bajo.

- Validacion modelo regresion multilineal 

Para la validación de este modelo se usaron los siguientes datos los cuales estan por fuera del rango en comaparación a los datos del entrenamiento.
```{r}
kable(datase_prueba_lineal)
```
Ya que se tenia el modelo con el dataset de entrenamiento, ahora se hace la prediccion con los nuevos datos
```{r }
predictors <- c( "INFRARED","ULTRASONIC")
sample.index <- sample(1:nrow(wall.distance)
                       ,nrow(wall.distance)*0.7
                       ,replace = F)
train.data  <-  wall.distance[sample.index
                                   ,c(predictors,"DISTANCE(cm)")
                                   ,drop=F]
test.data  <-  wall.distance[-sample.index
                                  ,c(predictors,"DISTANCE(cm)")
                                  ,drop=F]

model<- lm(`DISTANCE(cm)` ~ INFRARED + ULTRASONIC,train.data)
summary(model)
predictions <- predict(model,datase_prueba_lineal)
kable(predictions)
```

- Validacion modelo predictivo

Para la validacion del modelo predictivo se uso el siguiente dataset, este tiene valores fuera del rango en comparacion a los del entrenamiento
```{r}
kable(datasetprueba)
```
Teniendo ya el algoritmo Knn se procede a hacer la prueba con el nuevo dataset
```{r}
type.wall.distance$TYPE <-as.factor(type.wall.distance$TYPE)
datasetprueba$TYPE <- as.factor(datasetprueba$TYPE)


dummy <- dummyVars(" ~ TYPE",data = type.wall.distance)
dummy2 <- dummyVars(" ~ TYPE",data = datasetprueba)


newdata <- data.frame(predict(dummy,newdata = type.wall.distance))
type.wall.distance <- cbind(type.wall.distance,newdata)
newdata2 <- data.frame(predict(dummy2,newdata = datasetprueba))
datasetprueba<- cbind(datasetprueba,newdata2)

sample.index <- sample(1:nrow(type.wall.distance)
                       ,nrow(type.wall.distance)*0.7
                       ,replace = F)
predictors <- c("INFRARED","ULTRASONIC","TYPE.CONCAVA","TYPE.CONVEXA","TYPE.PLANA")


train.data  <-  type.wall.distance[sample.index
                                   ,c(predictors,"TYPE")
                                   ,drop=F]
test.data  <-  type.wall.distance[-sample.index
                                   ,c(predictors,"TYPE")
                                   ,drop=F]
##KNN
ctrl <- trainControl(method = "cv",p=0.7) #variable de control
Knnfit <- train(TYPE ~ INFRARED+ULTRASONIC+TYPE.CONCAVA+TYPE.CONVEXA+TYPE.PLANA
                ,data = train.data
                ,method = "knn", trControl = ctrl
                ,preProcess= c("range")
                ,tuneLength=20)

Knnpredict <- predict(Knnfit,newdata = datasetprueba)

confusionMatrix(Knnpredict
              ,datasetprueba$TYPE)

```

Con las respuestas de las predicciones del algoritmo se noto que si esta reconociendo correctamente los datos de validacion

## Conlusiones
- Debido a que el modelo lineal del sensor infrarojo no fue el esperado se pudo concluir que este tipo de sensores tienen gran variacion de sus datos, esto hace que la el modelo no pueda ser entrenado.

- Para el algoritmo Knn que reconoce el tipo de obstaculo se determino que el sensor ultrasonico es el que mas tiene presicion en los datos y este es la variable con mas relevancia en el modelo, es decir que el sensor ultrasonico es el fundamental para el entrenamiento del algoritmo.

- Debido a que los sensores tienen una respuesta computacionalmente muy rapida en comparacion a la mecanica, se tuvo que hacer uso de banderas en la programacion y un tiempo de espera para que captara solo un dato en el instante desead. De esta manera se logra una buena captacion de los datos para realizar la practica.
